{"cells":[{"cell_type":"markdown","metadata":{},"source":["- Link Model: https://huggingface.co/pitangent-ds/YOLOv8-human-detection-thermal\n","- Link Dataset: https://universe.roboflow.com/smart2/persondection-61bc2/dataset/5#\n","- Triển khai nhanh chóng trong tầm 3h với GPT4o, Kaggle, HuggingFace, Roboflow"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["# Cài đặt các thư viện cần thiết cho YOLOv8\n","!pip install ultralytics supervision huggingface_hub"]},{"cell_type":"markdown","metadata":{},"source":["# 1. Data"]},{"cell_type":"markdown","metadata":{},"source":["Link: https://universe.roboflow.com/smart2/persondection-61bc2/dataset/\n","Chọn YoloV8 - Show download code"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!pip install roboflow\n","\n","from roboflow import Roboflow\n","\n","# Nhập API key của bạn\n","rf = Roboflow(api_key=\"R1Rsh0Bx3eiHdB9aSGr2\")  # Thay thế bằng API key của bạn\n","\n","# Kết nối đến workspace và project trên Roboflow\n","project = rf.workspace(\"smart2\").project(\"persondection-61bc2\")\n","\n","# Chọn phiên bản project để tải dữ liệu\n","version = project.version(5)\n","\n","# Tải dataset dưới định dạng YOLOv8\n","dataset = version.download(\"yolov8\")\n"]},{"cell_type":"markdown","metadata":{},"source":["\n","Vẽ cấu trúc thư mục sau khi down về bằng markdown\n","```bash\n","/kaggle/working/PersonDection-5/\n","│\n","├── valid/\n","│   ├── images/\n","│   └── labels/\n","│\n","├── train/\n","│   ├── images/\n","│   └── labels/\n","│\n","├── test/\n","│   ├── images/\n","│   └── labels/\n","│\n","├── data.yaml\n","├── README.dataset.txt\n","├── README.roboflow.txt\n","└── roboflow.zip\n","```"]},{"cell_type":"markdown","metadata":{},"source":["Kiểm tra dataset: 8000 imgs train, 1000 valid, 1000 test"]},{"cell_type":"markdown","metadata":{},"source":["# 2. Test Model Trước Khi Huấn Luyện (Inference)"]},{"cell_type":"markdown","metadata":{},"source":["## 2.1 Test 1 ảnh"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Import các thư viện\n","from huggingface_hub import hf_hub_download\n","from ultralytics import YOLO\n","from supervision import Detections\n","import cv2 as cv\n","\n","# Tải mô hình YOLOv8 đã được huấn luyện\n","model_path = hf_hub_download(\n","    repo_id=\"pitangent-ds/YOLOv8-human-detection-thermal\",\n","    filename=\"model.pt\"\n",")\n","\n","# Khởi tạo mô hình từ file .pt đã tải\n","model = YOLO(model_path)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-output":false,"trusted":true},"outputs":[],"source":["# Hàm để chạy suy luận\n","def inference(image_path):\n","    # Đọc ảnh từ đường dẫn\n","    cv_image = cv.imread(image_path, cv.IMREAD_ANYCOLOR)\n","    \n","    # Chạy mô hình YOLO trên ảnh\n","    model_output = model(cv_image, conf=0.6, verbose=False)\n","    \n","    # Xử lý kết quả đầu ra\n","    detections = Detections.from_ultralytics(model_output[0])\n","    \n","    # Trả về kết quả suy luận\n","    return detections\n","\n","# Chạy suy luận trên ảnh cụ thể\n","detections = inference('/kaggle/working/PersonDection-5/test/images/video-4FRnNpmSmwktFJKjg-frame-001044-YYpRCPPF5hNtz2bkA_jpg.rf.a1fcf98068d16a6ffd22e9e6d4fbd1e6.jpg')\n","print(detections)\n"]},{"cell_type":"markdown","metadata":{},"source":["- xyxy: Tọa độ của bounding box (477.36, 258.71, 505.37, 318.28). Đây là các tọa độ điểm giới hạn của hộp bao quanh đối tượng trong ảnh. \n","    - x1, y1: Tọa độ của góc trên bên trái của hộp bao quanh (bounding box).\n","    - x2, y2: Tọa độ của góc dưới bên phải của hộp bao quanh.\n","    - Trong YOLO, gốc tọa độ (0, 0) thường nằm ở góc trên bên trái của hình ảnh, trục x nằm ngang từ trái sang phải và trục y nằm từ trên xuống dưới.\n","    - Trong hệ toạ độ Oxy Descartes, gốc tọa độ (0, 0) thường nằm ở giữa hệ trục, và trục y chạy từ dưới lên trên, trái ngược với YOLO.\n","- confidence: Độ tự tin của mô hình là 0.75238 (tức là 75.238%), cho thấy mức độ chắc chắn của mô hình về việc đối tượng được phát hiện là con người.\n","- class_id: 0 (tương ứng với lớp \"HUMAN\" trong mô hình của bạn).\n","- class_name: Tên lớp của đối tượng là HUMAN.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import cv2\n","import matplotlib.pyplot as plt\n","\n","# Đọc ảnh\n","image = cv2.imread('/kaggle/working/PersonDection-5/test/images/video-4FRnNpmSmwktFJKjg-frame-001044-YYpRCPPF5hNtz2bkA_jpg.rf.a1fcf98068d16a6ffd22e9e6d4fbd1e6.jpg')\n","\n","# Kiểm tra nếu ảnh được đọc thành công\n","if image is not None:\n","    # Lấy tọa độ bounding box\n","    x1, y1, x2, y2 = int(477.36), int(258.71), int(505.37), int(318.28)\n","\n","    # Vẽ bounding box trên ảnh\n","    cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)  # Màu xanh lá với độ dày 2px\n","\n","    # Ghi nhãn đối tượng\n","    cv2.putText(image, \"HUMAN\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n","\n","    # Chuyển đổi từ BGR sang RGB để hiển thị với matplotlib\n","    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","    # Hiển thị ảnh với matplotlib\n","    plt.imshow(image_rgb)\n","    plt.axis('off')  # Ẩn trục tọa độ\n","    plt.show()\n","else:\n","    print(\"Không thể đọc ảnh, vui lòng kiểm tra lại đường dẫn.\")\n"]},{"cell_type":"markdown","metadata":{},"source":["# 3. Đánh giá model trước, trong, sau huấn luyện"]},{"cell_type":"markdown","metadata":{},"source":["### Tóm tắt quy trình đánh giá mô hình trước, trong và sau khi huấn luyện:\n","\n","| **Giai đoạn**              | **Tập sử dụng**         | **Mục đích**                                                                                                  |\n","|----------------------------|-------------------------|---------------------------------------------------------------------------------------------------------------|\n","| **Trước khi training**      | Tập **validation**      | Đánh giá mô hình ban đầu để tinh chỉnh các **hyperparameters** mà không ảnh hưởng đến dữ liệu huấn luyện【66†source】【67†source】. |\n","| **Trong khi training**      | Tập **training** và **validation** | Mô hình học từ tập **training** và điều chỉnh tham số bằng cách đánh giá trên tập **validation**, nhằm tránh overfitting【60†source】【69†source】. |\n","| **Sau khi training xong**   | Tập **test**            | Đánh giá cuối cùng trên tập **test** để kiểm tra khả năng tổng quát hóa của mô hình với dữ liệu hoàn toàn mới【67†source】【69†source】. |\n","\n","### **Lý do không đánh giá mô hình trên tập test trước khi huấn luyện**:\n","\n","1. **Tránh dữ liệu rò rỉ (Data Leakage)**: Nếu đánh giá mô hình trên tập test trước khi huấn luyện, thông tin từ tập test có thể rò rỉ vào quá trình huấn luyện, khiến mô hình tối ưu hóa cho tập test và dẫn đến quá khớp (overfitting)【66†source】【69†source】.\n","\n","2. **Tập test dành cho đánh giá cuối cùng**: Tập test được giữ lại để đánh giá khả năng tổng quát hóa của mô hình sau khi tất cả các bước huấn luyện và tinh chỉnh đã hoàn tất. Sử dụng tập test trước sẽ làm mất tính khách quan của đánh giá cuối cùng【67†source】【68†source】.\n","\n","3. **Tập validation phù hợp cho việc tinh chỉnh**: Trong quá trình huấn luyện, tập validation được sử dụng để đánh giá và điều chỉnh các hyperparameter. Việc này giúp mô hình cải thiện mà không ảnh hưởng đến tính trung lập của tập test【69†source】.\n","\n","4. **Đảm bảo kết quả đáng tin cậy**: Nếu tập test được giữ nguyên cho đến cuối cùng, kết quả đánh giá sẽ phản ánh đúng hiệu suất thực sự của mô hình trên dữ liệu chưa từng gặp【67†source】【66†source】.\n","\n","### Tham khảo:\n","- [Training Set vs Validation Set vs Test Set](66)\n","- [How To Validate A Model In Machine Learning](68)\n","- [Train, Test, and Validation Sets](69)"]},{"cell_type":"markdown","metadata":{},"source":["Trong file `data.yaml`, 2 tập được sử dụng cho quá trình huấn luyện là:\n","- `train: ../train/images` (tập huấn luyện)\n","- `val: ../valid/images` (tập validation)\n","\n","Tập test (`test: ../test/images`) sẽ không được sử dụng trong quá trình huấn luyện, mà chỉ dùng để đánh giá cuối cùng sau khi mô hình đã được huấn luyện xong."]},{"cell_type":"markdown","metadata":{},"source":["- metrics_val: Đánh giá mô hình trước huấn luyện trên tập validation.\n","- model.train(): Huấn luyện mô hình với dữ liệu huấn luyện (train) và kiểm tra trên dữ liệu xác thực (val) để điều chỉnh tham số.\n","- metrics_test: Đánh giá mô hình sau huấn luyện trên tập test, đảm bảo rằng mô hình có khả năng tổng quát hóa tốt trên dữ liệu mới."]},{"cell_type":"markdown","metadata":{},"source":["## 3.1 Đánh giá mô hình trước khi huấn luyện (trên tập validation):"]},{"cell_type":"markdown","metadata":{},"source":["- YOLOv8 đã có các cơ chế tích hợp sẵn để xử lý dữ liệu nhanh chóng và hiệu quả như sử dụng DataLoader của PyTorch, batching, pre-fetching, và caching. Bạn chỉ cần tinh chỉnh một số tham số như `workers` hoặc `cache` nếu muốn tăng hiệu suất. Không cần tự viết lại DataLoader trừ khi bạn muốn tùy chỉnh sâu hơn.\n","\n","Dưới đây là bảng được mở rộng để giải thích chi tiết các cơ chế tối ưu hóa dữ liệu của **YOLOv8**:\n","\n","| **Phương pháp**                   | **Giải thích**                                                                                                                                                                                                                                     | **Ví dụ sử dụng**                                                                                          |\n","|------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------|\n","| **Batching**                       | Xử lý **nhiều hình ảnh trong một batch** thay vì xử lý từng ảnh riêng lẻ. Điều này giúp GPU hoặc CPU xử lý nhiều dữ liệu đồng thời, tận dụng tốt hơn tài nguyên phần cứng. Nó cũng giúp giảm overhead khi chuyển dữ liệu giữa CPU và GPU.  | Tự động trong YOLOv8 khi gọi hàm `train()`.                                                                 |\n","| **Pre-fetching**                   | **Pre-fetching** là quá trình nạp trước dữ liệu vào bộ nhớ trước khi cần thiết. Bằng cách đó, khi mô hình cần dữ liệu, dữ liệu đã sẵn sàng trong bộ nhớ, giảm thời gian chờ. Điều này giúp tránh **độ trễ I/O** khi nạp dữ liệu từ ổ cứng. | Được tích hợp sẵn trong `DataLoader` của YOLOv8. Không cần tùy chỉnh đặc biệt.                              |\n","| **Pinning memory**                 | **Pinning memory** là kỹ thuật lưu dữ liệu vào một vùng bộ nhớ không thể bị hoán đổi ra đĩa. Khi dữ liệu đã được \"pinned\", việc chuyển dữ liệu từ bộ nhớ CPU sang GPU sẽ nhanh hơn vì hệ thống không phải di chuyển dữ liệu qua các vùng nhớ khác. | Được hỗ trợ sẵn trong PyTorch và YOLOv8. Thường hoạt động khi `pin_memory=True` trong `DataLoader`.          |\n","| **Tăng số lượng worker**           | Sử dụng **nhiều worker** để nạp dữ liệu song song. Thay vì chỉ có một luồng đọc và nạp dữ liệu, có thể sử dụng nhiều worker để xử lý việc đọc dữ liệu đồng thời, giảm thời gian chờ đợi khi tải hình ảnh lớn hoặc dữ liệu nhiều.          | `model.train(data='data.yaml', epochs=50, imgsz=640, workers=4)`                                             |\n","| **Cache dữ liệu**                  | **Lưu dữ liệu vào bộ nhớ đệm (cache)** để giảm thời gian tải dữ liệu từ ổ cứng. Khi dữ liệu được lưu trong bộ nhớ đệm, các lần truy cập sau đó sẽ nhanh hơn, đặc biệt hữu ích khi làm việc với dữ liệu lớn mà không cần tải lại từ đĩa.    | `model.train(data='data.yaml', epochs=50, imgsz=640, cache=True)`                                            |\n","| **Mixed Precision Training (FP16)**| **Mixed precision** sử dụng cả **FP16 và FP32** trong quá trình huấn luyện. FP16 (16-bit floating point) giúp tăng tốc độ tính toán trên GPU bằng cách xử lý nhiều giá trị hơn mỗi chu kỳ, giảm yêu cầu bộ nhớ và tăng hiệu suất mà vẫn giữ độ chính xác với FP32 khi cần. | `model.train(data='data.yaml', epochs=50, imgsz=640, half=True)`                                             |\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from ultralytics import YOLO\n","\n","# Tải mô hình YOLOv8n đã được huấn luyện sẵn\n","model = YOLO(\"yolov8n.pt\")\n","\n","# Chạy đánh giá trên tập validation\n","metrics_val = model.val(data='/kaggle/working/PersonDection-5/data.yaml')  # Sử dụng tập validation\n","\n","# In các chỉ số đánh giá trước khi huấn luyện\n","print(\"Đánh giá trước khi huấn luyện trên tập validation:\")\n","print(f\"Precision: {metrics_val.box.map50:.3f}\")\n","print(f\"Recall: {metrics_val.box.map:.3f}\")\n","print(f\"mAP@0.5: {metrics_val.box.map50:.3f}\")\n","print(f\"mAP@0.5:0.95: {metrics_val.box.map:.3f}\")\n"]},{"cell_type":"markdown","metadata":{},"source":["Output sau khi run \n","```bash\n","runs/\n","└── detect/\n","    ├── val/\n","    ├── val2/\n","    ├── val3/\n","    └── val4/\n","```"]},{"cell_type":"markdown","metadata":{},"source":["Dưới đây là bảng tóm tắt chi tiết các chỉ số đánh giá trước khi huấn luyện lại mô hình YOLOv8:\n","\n","| **Chỉ Số**            | **Ý Nghĩa**                                                                                          | **Giá Trị**         |\n","|-----------------------|------------------------------------------------------------------------------------------------------|---------------------|\n","| **Precision**          | Tỉ lệ giữa số dự đoán đúng (true positives) và tổng số các dự đoán (true positives + false positives). Precision cao nghĩa là mô hình ít dự đoán sai. | `metrics.box.map50` |\n","| **Recall**             | Tỉ lệ giữa số dự đoán đúng và tổng số đối tượng thực sự có (true positives + false negatives). Recall cao nghĩa là mô hình phát hiện tốt các đối tượng. | `metrics.box.map`   |\n","| **mAP@0.5**            | Mean Average Precision tại ngưỡng IoU = 0.5. mAP đo lường độ chính xác của dự đoán khi yêu cầu độ chồng lấn giữa các hộp giới hạn (bounding boxes) là 50%. | `metrics.box.map50` |\n","| **mAP@0.5:0.95**       | Mean Average Precision trung bình qua nhiều ngưỡng IoU từ 0.5 đến 0.95 (với bước nhảy 0.05). Đây là chỉ số tổng hợp, phản ánh độ chính xác của mô hình qua nhiều mức yêu cầu khác nhau về độ chồng lấn. | `metrics.box.map`   |\n","\n","### Giải thích:\n","- **Precision** và **Recall** là hai chỉ số cơ bản để đánh giá khả năng dự đoán đúng của mô hình.\n","- **mAP@0.5** và **mAP@0.5:0.95** là những chỉ số tổng hợp đo lường khả năng dự đoán chính xác qua các ngưỡng IoU khác nhau, trong đó mAP@0.5 thường được sử dụng rộng rãi trong các bài toán phát hiện đối tượng."]},{"cell_type":"markdown","metadata":{},"source":["- Precision 0.526 và mAP@0.5 0.526 là mức độ khá trung bình, nhưng điều này chỉ là trước khi huấn luyện, có nghĩa là mô hình chưa được tối ưu và chỉ dựa trên mô hình YOLOv8 cơ bản.\n","- Recall 0.333 khá thấp, chỉ ra rằng mô hình hiện tại không phát hiện được nhiều đối tượng trong dữ liệu. Điều này rất phổ biến trước khi huấn luyện vì mô hình chưa học được nhiều thông tin từ dữ liệu cụ thể.\n","- mAP@0.5:0.95 0.333: Đây là một chỉ số quan trọng thể hiện mức độ tổng quát hóa của mô hình khi các yêu cầu về độ chồng lấn (IoU) càng khắt khe hơn. Với chỉ số thấp, mô hình trước huấn luyện khó có khả năng dự đoán chính xác khi các đối tượng trong ảnh bị chồng chéo phức tạp."]},{"cell_type":"markdown","metadata":{},"source":["## 3.2 Huấn luyện mô hình trên tập training và validation:Huấn luyện mô hình trên tập training và validation:"]},{"cell_type":"markdown","metadata":{},"source":["### Bảng tóm tắt về thời gian huấn luyện và các phương pháp tăng tốc:\n","\n","| **Yếu tố**                | **Dự tính/Khuyến nghị**                                                               |\n","|---------------------------|----------------------------------------------------------------------------------------|\n","| **Số lượng ảnh**           | 8000 ảnh huấn luyện, 1000 ảnh xác thực.                                                |\n","| **Thời gian huấn luyện**   | 50-250 phút (khoảng 1 đến 4 giờ) trên GPU Tesla T4 (50 epochs, imgsz=640x640).        |\n","| **Sử dụng mô hình nhẹ hơn**| Dùng YOLOv8n (nano) để giảm thời gian huấn luyện, nhưng có thể giảm độ chính xác.      |\n","| **Giảm kích thước ảnh**    | Giảm kích thước ảnh từ 640x640 xuống 416x416 để tăng tốc độ huấn luyện.               |\n","| **Giảm số lượng epochs**   | Thử huấn luyện với 30 epochs để rút ngắn thời gian và theo dõi kết quả sau đó.        |\n","| **Mixed Precision Training**| Sử dụng huấn luyện với precision hỗn hợp (`half=True`) để tăng tốc độ huấn luyện.     |\n"]},{"cell_type":"markdown","metadata":{},"source":["### Kaggle sau khi huấn luyện model được lưu vào đâu, ta nên log lại vào wandb hoặc mlFlow không?"]},{"cell_type":"markdown","metadata":{},"source":["Dưới đây là bảng tóm tắt về các phương pháp lưu mô hình trên Kaggle và so sánh giữa **W&B** và **MLflow** để log quá trình huấn luyện:\n","\n","| **Phương pháp**                                | **Mô tả chi tiết**                                                                                                     |\n","|-------------------------------------------------|------------------------------------------------------------------------------------------------------------------------|\n","| **Lưu mô hình trên Kaggle**                    | Sau khi huấn luyện, mô hình được lưu trong thư mục `runs/` (ví dụ: `runs/train/exp/best.pt`). Bạn có thể tải mô hình xuống từ Kaggle bằng lệnh API. |\n","| **Thời gian lưu trên Kaggle**                  | Mô hình được lưu tự động sau khi hoàn thành huấn luyện. Nếu không lưu trữ, kết quả có thể bị mất sau khi session Kaggle kết thúc. |\n","| **Sử dụng W&B để log**                         | - Giúp theo dõi quá trình huấn luyện (loss, accuracy, mAP, etc.).<br> - Lưu trữ mô hình và cho phép so sánh các phiên bản mô hình khác nhau. <br> - Cung cấp giao diện trực quan để theo dõi quá trình huấn luyện. |\n","| **Sử dụng MLflow để log**                      | - Tương tự như W&B, giúp quản lý và lưu trữ mô hình. <br> - Dễ dàng log hyperparameters, metrics, và lưu các phiên bản mô hình khác nhau. |\n","| **Cách sử dụng W&B trong Kaggle**              | ```python<br> import wandb <br> wandb.init(project=\"tên_dự_án\", entity=\"tên_người_dùng\") <br> model.train(data='data.yaml', log_artifacts=True) ``` |\n","| **Cách sử dụng MLflow trong Kaggle**           | ```python<br> import mlflow <br> mlflow.start_run() <br> mlflow.log_param(\"epochs\", 50) <br> mlflow.log_metric(\"mAP@0.5\", metrics_val.box.map50) <br> mlflow.end_run() ``` |\n","\n","\n","\n","### **So sánh giữa W&B và MLflow**\n","\n","| **Tiêu chí**                   | **Weights & Biases (W&B)**                                                                                          | **MLflow**                                                                                                           |\n","|--------------------------------|---------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------|\n","| **Giao diện người dùng (UI)**  | Giao diện trực quan, dễ dàng chia sẻ và theo dõi theo thời gian thực giữa các nhóm.                                | Giao diện đơn giản, dễ quản lý các phiên bản và mô hình nhưng ít trực quan hơn.                                      |\n","| **Khả năng log dữ liệu**       | Hỗ trợ log tất cả các thông số, biểu đồ, mô hình một cách chi tiết và theo thời gian thực.                        | Log hyperparameters, metrics và phiên bản mô hình, nhưng ít tính năng trực quan hơn W&B.                             |\n","| **Cộng đồng và tích hợp**      | Tích hợp tốt với nhiều framework (PyTorch, TensorFlow) và có cộng đồng lớn.                                        | Tích hợp tốt với Databricks và phổ biến trong doanh nghiệp nhờ khả năng quản lý mô hình.                             |\n","| **Tính năng**                  | Có các tính năng nổi bật như lưu checkpoints, visualizations, dễ dàng chia sẻ dự án.                               | Quản lý và lưu trữ phiên bản mô hình, phù hợp với môi trường doanh nghiệp và sản xuất.                               |\n","| **Tốc độ tích hợp**            | Dễ thiết lập và tích hợp nhanh chóng vào các dự án machine learning.                                               | Thiết lập dễ dàng nhưng ít trực quan hơn so với W&B.                                                                 |\n","| **Dùng miễn phí**              | Có phiên bản miễn phí với các tính năng cơ bản.                                                                    | Hoàn toàn miễn phí và mã nguồn mở.                                                                                  |\n","| **Môi trường hỗ trợ**          | Chạy tốt trên các nền tảng cloud, hỗ trợ đầy đủ trên môi trường online/server.                                    | Không hỗ trợ đầy đủ UI trên Kaggle, cần sử dụng **MLflow Tracking Server** hoặc chạy môi trường cục bộ để truy cập log và UI. |\n","\n","### **Lưu ý khi sử dụng MLflow trên Kaggle**:\n","- **MLflow UI trên Kaggle**: Kaggle không hỗ trợ trực tiếp MLflow UI, nhưng bạn có thể tải xuống file log hoặc chạy môi trường cục bộ để xem chi tiết log từ MLflow.\n","- **Sử dụng MLflow Tracking Server**: Nếu bạn muốn log vào một MLflow tracking server từ xa, có thể cấu hình server qua URL:\n","   ```python\n","   mlflow.set_tracking_uri(\"http://your-mlflow-server\")\n","   ```\n","\n","\n","\n","\n","#### **Kết luận**:\n","- **W&B** phù hợp nếu bạn cần một giao diện trực quan, dễ dàng chia sẻ kết quả và theo dõi quá trình huấn luyện theo thời gian thực.\n","- **MLflow** phù hợp hơn cho việc quản lý và theo dõi các phiên bản mô hình trong môi trường sản xuất, đặc biệt là trong các doanh nghiệp【67†source】【68†source】【69†source】."]},{"cell_type":"markdown","metadata":{},"source":["Mình chọn: log vào MLflow vì mình chưa dùng bao giờ (W&B mình từng dùng rùi)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!pip install wandb\n","!pip install -U ipywidgets # cập nhật từ 7.7.1 lên 8.0 "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import os\n","import wandb\n","\n","# # Need Enter key\n","# wandb.login()\n","\n","# # Đăng nhập bằng biến môi trường\n","# wandb.login(key=os.getenv(\"WANDB_API_KEY\"))\n","\n","# Đăng nhập trực tiếp vào WandB bằng API key\n","wandb.login(key=\"c8767797aae76cbcd389ff29929ace1ac3021161\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Tải mô hình YOLOv8n\n","model = YOLO(\"yolov8n.pt\")\n","\n","# Huấn luyện mô hình và tích hợp WandB với tên chi tiết\n","model.train(\n","    data='/kaggle/working/PersonDection-5/data.yaml',  # Đường dẫn tới file cấu hình dữ liệu\n","    epochs=3,                   # Số lượng epochs\n","    imgsz=640,                   # Kích thước ảnh\n","    project=\"ThermalHumanDetect_YOLO\",     # Tên project trên WandB\n","    name=\"YOLOv8n_ThermalHumanDetect_img640_epochs3_mixedPrecision_noAug_lr0.01\",  # name RUN, Tên chi tiết\n","    save_period=1,               # Lưu kết quả mỗi 1 epochs\n","    device=\"cuda\",               # Sử dụng GPU\n","    half=True,                   # Mixed precision để tăng tốc độ huấn luyện\n","    lr0=0.01                     # Learning rate ban đầu là 0.01\n",")\n"]},{"cell_type":"markdown","metadata":{},"source":["```bash\n","Ultralytics 8.3.22 🚀 Python-3.10.14 torch-2.4.0 CUDA:0 (Tesla T4, 15095MiB)\n","engine/trainer: task=detect, mode=train, model=yolov8n.pt, data=/kaggle/working/PersonDection-5/data.yaml, epochs=3, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=1, cache=False, device=cuda, workers=8, project=ThermalHumanDetect_YOLO, name=YOLOv8n_ThermalHumanDetect_img640_epochs3_mixedPrecision_noAug_lr0.012, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=True, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=ThermalHumanDetect_YOLO/YOLOv8n_ThermalHumanDetect_img640_epochs3_mixedPrecision_noAug_lr0.012\n","Overriding model.yaml nc=80 with nc=1\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n","  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n","  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n"," 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n"," 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n","Model summary: 225 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n","\n","Transferred 319/355 items from pretrained weights\n","TensorBoard: Start with 'tensorboard --logdir ThermalHumanDetect_YOLO/YOLOv8n_ThermalHumanDetect_img640_epochs3_mixedPrecision_noAug_lr0.012', view at http://localhost:6006/\n","Tracking run with wandb version 0.18.3\n","Run data is saved locally in /kaggle/working/wandb/run-20241025_064049-jidy5o7a\n","Syncing run YOLOv8n_ThermalHumanDetect_img640_epochs3_mixedPrecision_noAug_lr0.012 to Weights & Biases (docs)\n","View project at https://wandb.ai/doanngoccuong_nh/ThermalHumanDetect_YOLO\n","View run at https://wandb.ai/doanngoccuong_nh/ThermalHumanDetect_YOLO/runs/jidy5o7a\n","Freezing layer 'model.22.dfl.conv.weight'\n","AMP: running Automatic Mixed Precision (AMP) checks...\n","AMP: checks passed ✅\n","train: Scanning /kaggle/working/PersonDection-5/train/labels.cache... 7037 images, 668 backgrounds, 0 corrupt: 100%|██████████| 7037/7037 [00:00<?, ?it/s]\n","albumentations: Blur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\n","RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","val: Scanning /kaggle/working/PersonDection-5/valid/labels.cache... 887 images, 0 backgrounds, 0 corrupt: 100%|██████████| 887/887 [00:00<?, ?it/s]\n","Plotting labels to ThermalHumanDetect_YOLO/YOLOv8n_ThermalHumanDetect_img640_epochs3_mixedPrecision_noAug_lr0.012/labels.jpg... \n","optimizer: 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","optimizer: AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n","TensorBoard: model graph visualization added ✅\n","Image sizes 640 train, 640 val\n","Using 4 dataloader workers\n","Logging results to ThermalHumanDetect_YOLO/YOLOv8n_ThermalHumanDetect_img640_epochs3_mixedPrecision_noAug_lr0.012\n","Starting training for 3 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        1/3      2.29G      1.425      1.839      1.369         41        640: 100%|██████████| 440/440 [01:18<00:00,  5.60it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:05<00:00,  5.00it/s]\n","                   all        887       2124      0.578      0.583      0.583      0.319\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        2/3      2.22G      1.398      1.423      1.358         52        640: 100%|██████████| 440/440 [01:14<00:00,  5.89it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:05<00:00,  5.01it/s]\n","                   all        887       2124      0.749      0.659      0.744      0.416\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        3/3      2.25G      1.305      1.227      1.297         41        640: 100%|██████████| 440/440 [01:13<00:00,  5.97it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:05<00:00,  4.87it/s]\n","                   all        887       2124      0.807      0.713      0.808      0.499\n","\n","3 epochs completed in 0.076 hours.\n","Optimizer stripped from ThermalHumanDetect_YOLO/YOLOv8n_ThermalHumanDetect_img640_epochs3_mixedPrecision_noAug_lr0.012/weights/last.pt, 6.2MB\n","Optimizer stripped from ThermalHumanDetect_YOLO/YOLOv8n_ThermalHumanDetect_img640_epochs3_mixedPrecision_noAug_lr0.012/weights/best.pt, 6.2MB\n","\n","Validating ThermalHumanDetect_YOLO/YOLOv8n_ThermalHumanDetect_img640_epochs3_mixedPrecision_noAug_lr0.012/weights/best.pt...\n","Ultralytics 8.3.22 🚀 Python-3.10.14 torch-2.4.0 CUDA:0 (Tesla T4, 15095MiB)\n","Model summary (fused): 168 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:06<00:00,  4.09it/s]\n","                   all        887       2124      0.808      0.713      0.808      0.499\n","Speed: 0.2ms preprocess, 2.0ms inference, 0.0ms loss, 1.3ms postprocess per image\n","Results saved to ThermalHumanDetect_YOLO/YOLOv8n_ThermalHumanDetect_img640_epochs3_mixedPrecision_noAug_lr0.012\n","Loading widget...\n","Run history:\n","\n","lr/pg0\t▁█▁\n","lr/pg1\t▁█▁\n","lr/pg2\t▁█▁\n","metrics/mAP50(B)\t▁▆█\n","metrics/mAP50-95(B)\t▁▅█\n","metrics/precision(B)\t▁▆█\n","metrics/recall(B)\t▁▅█\n","model/GFLOPs\t▁\n","model/parameters\t▁\n","model/speed_PyTorch(ms)\t▁\n","train/box_loss\t█▆▁\n","train/cls_loss\t█▃▁\n","train/dfl_loss\t█▇▁\n","val/box_loss\t█▅▁\n","val/cls_loss\t█▄▁\n","val/dfl_loss\t█▆▁\n","\n","Run summary:\n","\n","lr/pg0\t0.00068\n","lr/pg1\t0.00068\n","lr/pg2\t0.00068\n","metrics/mAP50(B)\t0.8082\n","metrics/mAP50-95(B)\t0.49928\n","metrics/precision(B)\t0.80845\n","metrics/recall(B)\t0.71328\n","model/GFLOPs\t8.194\n","model/parameters\t3011043\n","model/speed_PyTorch(ms)\t2.104\n","train/box_loss\t1.30457\n","train/cls_loss\t1.2274\n","train/dfl_loss\t1.29697\n","val/box_loss\t1.27087\n","val/cls_loss\t1.04561\n","val/dfl_loss\t1.24087\n","\n","View run YOLOv8n_ThermalHumanDetect_img640_epochs3_mixedPrecision_noAug_lr0.012 at: https://wandb.ai/doanngoccuong_nh/ThermalHumanDetect_YOLO/runs/jidy5o7a\n","View project at: https://wandb.ai/doanngoccuong_nh/ThermalHumanDetect_YOLO\n","Synced 5 W&B file(s), 0 media file(s), 10 artifact file(s) and 21 other file(s)\n","Find logs at: ./wandb/run-20241025_064049-jidy5o7a/logs\n","ultralytics.utils.metrics.DetMetrics object with attributes:\n","\n","ap_class_index: array([0])\n","box: ultralytics.utils.metrics.Metric object\n","confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7ccbd7214430>\n","\n","\n","curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n","curves_results: [[array([     ...] \n","\n","fitness: 0.5301676030741032\n","keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n","maps: array([    0.49928])\n","names: {0: 'person'}\n","plot: True\n","results_dict: {'metrics/precision(B)': 0.8084457451683595, 'metrics/recall(B)': 0.713276836158192, 'metrics/mAP50(B)': 0.8081973767947674, 'metrics/mAP50-95(B)': 0.4992754059940293, 'fitness': 0.5301676030741032}\n","save_dir: PosixPath('ThermalHumanDetect_YOLO/YOLOv8n_ThermalHumanDetect_img640_epochs3_mixedPrecision_noAug_lr0.012')\n","speed: {'preprocess': 0.18920893061658306, 'inference': 2.026759785218868, 'loss': 0.0005698392194986613, 'postprocess': 1.2812764964485384}\n","task: 'detect'\n","```"]},{"cell_type":"markdown","metadata":{},"source":["#### YOLOv8n_ThermalHumanDetect_img640_epochs3_mixedPrecision_noAug_lr0.01 - kết quả thu được\n","\n","| **Thông số/Kết quả**              | **Giá trị**                       |\n","|-----------------------------------|------------------------------------|\n","| **Precision (Độ chính xác)**      | 0.808 (80.8%)                     |\n","| **Recall (Khả năng phát hiện)**   | 0.713 (71.3%)                     |\n","| **mAP@0.5**                       | 0.808 (80.8%)                     |\n","| **mAP@0.5:0.95**                  | 0.499 (49.9%)                     |\n","| **Epoch 1** - Precision           | 0.578                             |\n","| **Epoch 1** - Recall              | 0.583                             |\n","| **Epoch 1** - mAP@0.5             | 0.583                             |\n","| **Epoch 1** - mAP@0.5:0.95        | 0.319                             |\n","| **Epoch 2** - Precision           | 0.749                             |\n","| **Epoch 2** - Recall              | 0.659                             |\n","| **Epoch 2** - mAP@0.5             | 0.744                             |\n","| **Epoch 2** - mAP@0.5:0.95        | 0.416                             |\n","| **Epoch 3** - Precision           | 0.808                             |\n","| **Epoch 3** - Recall              | 0.713                             |\n","| **Epoch 3** - mAP@0.5             | 0.808                             |\n","| **Epoch 3** - mAP@0.5:0.95        | 0.499                             |\n","| **Kích thước ảnh**                | 640                               |\n","| **Số lượng ảnh huấn luyện**       | 7037                              |\n","| **Số lượng ảnh kiểm tra**         | 887                               |\n","| **Box Loss (Epoch 3)**            | 1.305                             |\n","| **Class Loss (Epoch 3)**          | 1.227                             |\n","| **DFL Loss (Epoch 3)**            | 1.297                             |\n","| **Optimizer**                     | AdamW (lr=0.002)                  |\n","| **AMP (Automatic Mixed Precision)**| Được kích hoạt                     |\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["Dưới đây là bảng tóm tắt chi tiết các chỉ số đánh giá trước và sau khi huấn luyện mô hình YOLOv8:\n","\n","| **Chỉ Số**        | **Ý Nghĩa**                                                                                          | **Thế nào là tốt?**                                                                                     | **Kỳ vọng với bài toán**                                                                                   | **Trước huấn luyện** | **Sau huấn luyện (3 epochs)** |\n","|-------------------|------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------|-----------------------|------------------------------|\n","| **Precision**      | Tỉ lệ giữa số dự đoán đúng (true positives) và tổng số các dự đoán (true positives + false positives). Precision cao nghĩa là mô hình ít dự đoán sai. | Precision cao thể hiện độ chính xác của mô hình trong việc đưa ra dự đoán đúng.                          | Precision cao giúp giảm số lượng các dự đoán sai, đặc biệt trong các ứng dụng đòi hỏi độ chính xác cao.    | 0.526                 | 0.808                        |\n","| **Recall**         | Tỉ lệ giữa số dự đoán đúng và tổng số đối tượng thực sự có (true positives + false negatives). Recall cao nghĩa là mô hình phát hiện tốt các đối tượng. | Recall cao thể hiện khả năng phát hiện đầy đủ các đối tượng trong dữ liệu.                               | Kỳ vọng mô hình không bỏ sót các đối tượng quan trọng, đặc biệt trong các tình huống có nhiều đối tượng nhỏ hoặc ẩn. | 0.333                 | 0.713                        |\n","| **mAP@0.5**        | Mean Average Precision tại ngưỡng IoU = 0.5, đo lường độ chính xác của dự đoán khi yêu cầu độ chồng lấn giữa các hộp giới hạn là 50%. | mAP@0.5 cao cho thấy mô hình có khả năng phát hiện tốt các đối tượng với độ chính xác hộp giới hạn (bounding boxes). | Kỳ vọng mô hình đạt mAP@0.5 cao để tối ưu hóa khả năng phát hiện đối tượng trong các bài toán yêu cầu độ chính xác cao. | 0.526                 | 0.808                        |\n","| **mAP@0.5:0.95**   | Mean Average Precision trung bình qua nhiều ngưỡng IoU từ 0.5 đến 0.95. Chỉ số này phản ánh khả năng dự đoán chính xác với các mức độ chồng lấn khác nhau. | mAP@0.5:0.95 cao thể hiện khả năng tổng quát hóa tốt của mô hình, đặc biệt trong các bài toán có các đối tượng chồng lấn. | Kỳ vọng cải thiện mAP@0.5:0.95 để mô hình hoạt động tốt hơn khi đối tượng có các mức độ chồng lấn phức tạp.          | 0.333                 | 0.499                        |\n","\n","### **Nhận xét**:\n","Mô hình đã cải thiện rõ rệt các chỉ số **precision**, **recall**, và **mAP@0.5** sau khi huấn luyện 3 epochs. Chỉ số **mAP@0.5:0.95** cũng đã tăng lên, tuy nhiên vẫn còn cần cải thiện thêm để đạt hiệu suất tốt hơn trong các tình huống đối tượng có mức độ chồng lấn cao."]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"markdown","metadata":{},"source":["\n","| **Khái niệm** | **Chức năng**                                                                                              | **Trong code trên thì**                                                                                          |\n","|---------------|------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------|\n","| **Project**   | Là nơi lưu trữ tất cả các lần huấn luyện (**run**) liên quan đến một dự án cụ thể.                           | `project=\"ThermalHumanDetect_YOLO\"` là tên của dự án chứa tất cả các lần huấn luyện liên quan đến phát hiện người bằng ảnh nhiệt. |\n","| **Run**       | Là một phiên bản cụ thể của quá trình huấn luyện hoặc inference, lưu lại toàn bộ thông tin về lần chạy đó.    | `name=\"YOLOv8n_ThermalHumanDetect_img640_epochs5_mixedPrecision_noAug_lr0.01\"` là tên của lần huấn luyện cụ thể. |\n","| **ID**        | Là mã định danh ngẫu nhiên do WandB gán tự động cho mỗi **run** để đảm bảo tính duy nhất.                   | Ví dụ: `jidy5o7a`. Đây là ID được WandB tự động tạo ra để nhận diện run duy nhất này.                            |\n","| **Artifact**  | Là tệp hoặc dữ liệu bạn lưu trữ lại, như trọng số mô hình hoặc tệp kết quả để quản lý và tái sử dụng.        | Artifact chưa được lưu rõ ràng trong đoạn mã, nhưng bạn có thể lưu trọng số mô hình (weights) sau khi huấn luyện. |\n","| **Model**     | Chính là mô hình học máy bạn đang huấn luyện hoặc inference, có thể được lưu lại như một artifact.           | Mô hình YOLOv8 được tải và huấn luyện: `model = YOLO(\"yolov8n.pt\")`.                                             |\n","| **Run Table** | Bảng liệt kê thông tin từ nhiều lần **run** khác nhau để dễ dàng so sánh kết quả giữa các lần chạy.          | Bảng **Run Table** hiển thị các chỉ số từ nhiều lần chạy, không được trực tiếp đề cập trong code nhưng có thể xem trong WandB dashboard. |\n","\n","### Giải thích:\n","- **ID** là mã duy nhất mà WandB tạo ra để đảm bảo không có hai run nào có cùng ID, ngay cả khi bạn đặt tên (**name**) cho nhiều lần chạy giống nhau.\n","- **Name** là tên bạn tự đặt, có thể trùng lặp hoặc tùy chỉnh để dễ nhận diện mục đích của run đó.\n","- **Run Table** là nơi bạn có thể xem tất cả các **run** trong một **project**, và so sánh các chỉ số như **loss**, **accuracy**, v.v., từ nhiều lần chạy khác nhau."]},{"cell_type":"markdown","metadata":{},"source":["Bổ sung bảng tóm tắt các phiên bản của **YOLOv8**:\n","\n","| **Phiên bản**  | **Tên đầy đủ**           | **Kích thước mô hình** | **Ưu điểm**                                        | **Nhược điểm**                       | **Ứng dụng**                                |\n","|----------------|--------------------------|------------------------|---------------------------------------------------|--------------------------------------|---------------------------------------------|\n","| **YOLOv8n**    | YOLOv8 Nano               | Nhỏ nhất                | Nhanh nhất, ít tài nguyên, phù hợp thiết bị nhúng | Độ chính xác thấp hơn                | Thiết bị di động, nhúng, edge devices       |\n","| **YOLOv8s**    | YOLOv8 Small              | Nhỏ                     | Cân bằng giữa tốc độ và độ chính xác              | Vẫn có thể thiếu độ chính xác        | Ứng dụng yêu cầu tốc độ nhanh, độ chính xác khá |\n","| **YOLOv8m**    | YOLOv8 Medium             | Trung bình              | Độ chính xác cao hơn YOLOv8n và YOLOv8s           | Cần nhiều tài nguyên hơn             | Dự án cần cân bằng giữa tốc độ và độ chính xác |\n","| **YOLOv8l**    | YOLOv8 Large              | Lớn                     | Độ chính xác cao, phù hợp với bài toán phức tạp   | Chạy chậm hơn, yêu cầu nhiều tài nguyên | Bài toán yêu cầu độ chính xác cao          |\n","| **YOLOv8x**    | YOLOv8 Extra-Large        | Lớn nhất                | Độ chính xác cao nhất, dùng cho bài toán phức tạp | Yêu cầu tài nguyên tính toán rất lớn | Ứng dụng yêu cầu độ chính xác rất cao      |\n","\n","### Lưu ý:\n","- **YOLOv8n (nano)** là phiên bản **nhỏ nhất và nhanh nhất**, thích hợp cho các ứng dụng yêu cầu tốc độ cao với phần cứng hạn chế.\n","- **YOLOv8l (large)** và **YOLOv8x (extra-large)** là các phiên bản lớn hơn, mang lại độ chính xác cao hơn nhưng đòi hỏi nhiều tài nguyên tính toán hơn, thích hợp cho các ứng dụng cần độ chính xác tối đa.\n"]},{"cell_type":"markdown","metadata":{},"source":["Tóm tắt các lựa chọn mô hình YOLOv8 phù hợp cho **8000 ảnh train**, **1000 ảnh validation** và GPU **T4 x2** trên Kaggle:\n","\n","| **Phiên bản YOLOv8** | **Ưu tiên**                      | **Độ chính xác**                 | **Thời gian dự kiến (50 epochs)** | **Khuyến nghị**                                                                                 |\n","|-----------------------|----------------------------------|-----------------------------------|-----------------------------------|-------------------------------------------------------------------------------------------------|\n","| **YOLOv8n (Nano)**    | Tốc độ tối đa, tài nguyên nhẹ   | Thấp nhất                         | < 1 giờ                           | Phù hợp cho các thử nghiệm nhanh hoặc các ứng dụng cần tốc độ cao, chấp nhận độ chính xác thấp. |\n","| **YOLOv8s (Small)**   | Cân bằng giữa tốc độ và độ chính xác | Tốt, độ chính xác vừa phải         | 1-2 giờ                           | Lựa chọn tốt nếu cần cân bằng giữa hiệu suất và thời gian huấn luyện.                           |\n","| **YOLOv8m (Medium)**  | Độ chính xác cao hơn YOLOv8s    | Cao                               | 2-4 giờ                           | Phù hợp cho các bài toán yêu cầu độ chính xác cao hơn và sẵn sàng đợi lâu hơn để huấn luyện.    |\n","\n","### Gợi ý\n","- **YOLOv8s** là lựa chọn **cân bằng** giữa thời gian và độ chính xác cho bài toán của bạn.\n","- **YOLOv8m** nếu bạn cần **độ chính xác cao hơn** và có thể dành nhiều thời gian cho quá trình huấn luyện."]},{"cell_type":"markdown","metadata":{},"source":["## 3.3 Đánh giá mô hình sau khi huấn luyện (trên tập test):"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-25T06:45:49.176338Z","iopub.status.busy":"2024-10-25T06:45:49.175947Z","iopub.status.idle":"2024-10-25T06:46:01.385931Z","shell.execute_reply":"2024-10-25T06:46:01.384727Z","shell.execute_reply.started":"2024-10-25T06:45:49.176282Z"},"trusted":true},"outputs":[],"source":["# Đánh giá mô hình trên tập test\n","metrics_test = model.val(data='/kaggle/working/PersonDection-5/data.yaml', split=\"test\")\n","\n","# In các chỉ số sau huấn luyện\n","print(\"Kết quả đánh giá trên tập test sau huấn luyện:\")\n","print(f\"Precision: {metrics_test.box.map50:.3f}\")\n","print(f\"Recall: {metrics_test.box.map:.3f}\")\n","print(f\"mAP@0.5: {metrics_test.box.map50:.3f}\")\n","print(f\"mAP@0.5:0.95: {metrics_test.box.map:.3f}\")\n"]},{"cell_type":"markdown","metadata":{},"source":["## 3.4 ĐÁNH GIÁ "]},{"cell_type":"markdown","metadata":{},"source":["Dưới đây là bảng so sánh giữa **Kaggle** và **WandB** với các tùy chọn `save_period`, `save=True`, và `wandb.log_artifact()` khi huấn luyện YOLOv8:\n","\n","| **Nội dung lưu**            | **Kaggle**                                                                                                                                             | **WandB**                                                                                                                             |\n","|-----------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------|\n","| **Lưu kết quả mỗi epoch**   | , Kaggle lưu các chỉ số như `precision`, `recall`, `mAP` và các hình ảnh dự đoán (prediction images) sau mỗi epoch.                             | WandB tự động ghi nhận các chỉ số này lên giao diện trong mỗi epoch nhưng không lưu trọng số mô hình theo mặc định.                   |\n","| **Lưu trọng số mô hình (`.pt`)** mỗi 10 epochs (`save_period=10`, Mặc định `save=True`), | Kaggle lưu tệp trọng số mô hình `.pt` vào thư mục `weights` của project theo chu kỳ mỗi `save_period=10` epochs (ví dụ `epoch_10.pt`, `epoch_20.pt`). | WandB không tự động lưu trọng số mô hình vào mục Artifacts. Để lưu, bạn cần sử dụng `wandb.log_artifact()` theo cách thủ công【121†source】【122†source】.|\n","\n","### Lưu ý\n","- Nếu muốn lưu trọng số lên WandB, bạn có thể gọi `wandb.log_artifact()` sau các epoch nhất định để lưu thủ công lên Artifacts. Điều này sẽ giúp quản lý phiên bản trọng số mô hình trên WandB, hữu ích cho việc kiểm tra và so sánh sau này【123†source】【124†source】."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import wandb\n","from ultralytics import YOLO\n","\n","# Khởi tạo dự án WandB\n","wandb.init(project=\"ThermalHumanDetect_YOLO\")\n","\n","# Tải mô hình YOLOv8n\n","model = YOLO(\"yolov8n.pt\")\n","\n","# Tên mô hình để nhất quán khi lưu trên Kaggle và WandB\n","model_name = \"YOLOvn_ThermalHumanDetect_img640_epochs10_mixedPrecision_withAug_lr0.01\"\n","\n","# Định nghĩa hàm callback để lưu trọng số lên WandB sau mỗi epoch\n","def log_model_to_wandb(epoch, **kwargs):\n","    model_path = f\"runs/train/{model_name}/weights/epoch_{epoch}.pt\"\n","    artifact = wandb.Artifact(f\"{model_name}_weights_epoch_{epoch}\", type=\"model\")\n","    artifact.add_file(model_path)\n","    wandb.log_artifact(artifact)\n","\n","# Đăng ký callback cho quá trình huấn luyện\n","model.add_callback(\"on_epoch_end\", log_model_to_wandb)\n","\n","# Bắt đầu huấn luyện với callback\n","model.train(\n","    data='/kaggle/working/PersonDection-5/data.yaml',\n","    epochs=10,\n","    imgsz=640,\n","    project=\"ThermalHumanDetect_YOLO\",\n","    name=model_name,\n","    save=True,\n","    save_period=1,\n","    device=\"cuda\",\n","    half=True,\n","    lr0=0.01,\n","    augment=True\n",")\n"]},{"cell_type":"markdown","metadata":{},"source":["| **Chỉ Số**        | **Ý Nghĩa**                                                                                          | **Thế nào là tốt?**                                                                                     | **Validation - trước huấn luyện** | **Validation - 3 epochs - Yolov8s - No Augmentation** | **Validation - 15 epochs - Yolov8s - No Augmentation** | **Test - 15 epochs - Yolov8s - No Augmentation** |\n","|-------------------|------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------|-------------------------------|--------------------------|--------------------------|--------------------|\n","| **Time Training/Inference** | Thời gian huấn luyện hoặc suy luận cho mỗi lần đánh giá mô hình. | Thời gian ngắn giúp tối ưu hiệu suất mô hình. | N/A | 0.08 giờ | 0.4 giờ | 0.01 giờ |\n","| **Precision**      | Tỉ lệ giữa số dự đoán đúng (true positives) và tổng số các dự đoán (true positives + false positives). Precision cao nghĩa là mô hình ít dự đoán sai. | Precision cao thể hiện độ chính xác của mô hình trong việc đưa ra dự đoán đúng.                          | 0.526                        | 0.808                   | 0.865                   | 0.904             |\n","| **Recall**         | Tỉ lệ giữa số dự đoán đúng và tổng số đối tượng thực sự có (true positives + false negatives). Recall cao nghĩa là mô hình phát hiện tốt các đối tượng. | Recall cao thể hiện khả năng phát hiện đầy đủ các đối tượng trong dữ liệu.                               | 0.333                        | 0.713                   | 0.811                   | 0.597             |\n","| **mAP@0.5**        | Mean Average Precision tại ngưỡng IoU = 0.5, đo lường độ chính xác của dự đoán khi yêu cầu độ chồng lấn giữa các hộp giới hạn là 50%. | mAP@0.5 cao cho thấy mô hình có khả năng phát hiện tốt các đối tượng với độ chính xác hộp giới hạn (bounding boxes). | 0.526                        | 0.808                   | 0.898                   | 0.904             |\n","| **mAP@0.5:0.95**   | Mean Average Precision trung bình qua nhiều ngưỡng IoU từ 0.5 đến 0.95. Chỉ số này phản ánh khả năng dự đoán chính xác với các mức độ chồng lấn khác nhau. | mAP@0.5:0.95 cao thể hiện khả năng tổng quát hóa tốt của mô hình, đặc biệt trong các bài toán có các đối tượng chồng lấn. | 0.333                        | 0.499                   | 0.618                   | 0.597             |\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["- Trước khi huấn luyện: Khi thực hiện đánh giá ban đầu trên tập validation, mô hình YOLOv8 đạt Precision là 0.526, Recall là 0.333, mAP@0.5 là 0.526, và mAP@0.5:0.95 là 0.333. Đây là các chỉ số từ mô hình YOLOv8 cơ bản chưa được tối ưu hóa.\n","- Sau khi huấn luyện (3 epochs - Yolov8s - No Augmentation) – 0.08h (4.8min): Sau 3 epochs huấn luyện, các chỉ số cho thấy sự cải thiện đáng kể: Precision tăng lên 0.808, Recall đạt 0.713, mAP@0.5 là 0.808 và mAP@0.5:0.95 là 0.499. Những kết quả này thể hiện rằng mô hình đã học được đặc trưng quan trọng của đối tượng người trong các ảnh nhiệt.\n","- Sau khi huấn luyện (15 epochs - Yolov8s - No Augmentation) – 0.4h (24min): Sau 15 epochs huấn luyện, các chỉ số tiếp tục cải thiện với Precision đạt 0.865, Recall là 0.811, mAP@0.5 đạt 0.898 và mAP@0.5:0.95 đạt 0.618 trên tập validation. Điều này thể hiện rằng mô hình đã học tốt hơn về khả năng phát hiện và nhận diện đối tượng trong các điều kiện phức tạp.\n"]},{"cell_type":"markdown","metadata":{},"source":["![img](./img_reports/compare3version_15to30_firstSteps.png)"]},{"cell_type":"markdown","metadata":{},"source":["- YOLOv8n có thể cho kết quả cao hơn trong những bước đầu do cấu trúc nhẹ hơn, cho phép nó học nhanh hơn. Tuy nhiên, về lâu dài, YOLOv8m sẽ dần vượt qua với khả năng tối ưu hóa tốt hơn khi số lượng epochs tăng lên và mô hình hoàn thành các bước điều chỉnh tham số.\n","- Khi huấn luyện trong thời gian dài (nhiều epochs hơn), ta có thể mong đợi YOLOv8m sẽ vượt qua YOLOv8n nhờ khả năng tổng quát hóa tốt hơn với một lượng lớn tham số."]},{"cell_type":"markdown","metadata":{},"source":["| **Thuật ngữ** | **Ý nghĩa**                                                                                                   | **Chi tiết**                                                                                                                                                    |\n","|---------------|----------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n","| **Epoch**     | Một lượt hoàn thành toàn bộ tập dữ liệu huấn luyện.                                                            | Mỗi epoch mô hình sẽ xem qua toàn bộ dữ liệu một lần. Số lượng epoch được đặt trước và ảnh hưởng đến mức độ học của mô hình.                                      |\n","| **Batch**     | Phần nhỏ của tập dữ liệu được sử dụng để huấn luyện trong một lần cập nhật trọng số.                            | Thay vì dùng toàn bộ dữ liệu một lần, dữ liệu được chia thành nhiều batch nhỏ. Kích thước batch (batch size) là số mẫu trong mỗi batch, giúp tiết kiệm bộ nhớ.    |\n","| **Step**      | Một lần cập nhật trọng số dựa trên một batch.                                                                   | Mỗi step (hoặc iteration) tương ứng với một batch, nơi mô hình tính gradient và cập nhật trọng số. Số step trong một epoch = số mẫu dữ liệu chia cho batch size. |\n","\n","### Ví dụ\n","Nếu bạn có 1000 mẫu dữ liệu và batch size là 100, thì sẽ có 10 steps trong mỗi epoch.\n","\n","| Mối quan hệ                | Công thức                                                       |\n","|----------------------------|----------------------------------------------------------------|\n","| Số steps trong một epoch   | steps per epoch = total samples / batch size                  |"]},{"cell_type":"markdown","metadata":{},"source":["- Step có thể đại diện cho epoch nếu số lượng step và epoch là tương đương trong quá trình huấn luyện.\n","- Nếu step đại diện cho nhiều lần cập nhật (tức là nhiều batch nhỏ trong một epoch), thì có thể số step sẽ nhiều hơn số epoch."]},{"cell_type":"markdown","metadata":{},"source":["# Finish"]},{"cell_type":"markdown","metadata":{},"source":["\n","| **Chỉ Số**              | **Ý Nghĩa**                                                                                         | **Thế nào là tốt?**                                                                                      | **Validation - trước huấn luyện** | **Validation - 3 epochs - Yolov8s - No Augmentation** | **Validation - 15 epochs - Yolov8s - No Augmentation** | **Test - 15 epochs - Yolov8s - No Augmentation** | **Validation - 30 epochs - Yolov8m - withAug** | **Test - 30 epochs - Yolov8m - withAug** |\n","|-------------------------|-----------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------|----------------------------------|------------------------------------------------------|-----------------------------------------------------|---------------------------------------------------|------------------------------------------------------|----------------------------------------------|\n","| **Time Training/Inference** | Thời gian huấn luyện hoặc suy luận cho mỗi lần đánh giá mô hình.                                      | Thời gian ngắn giúp tối ưu hiệu suất mô hình.                                                             | N/A                              | 0.08 giờ                                             | 0.4 giờ                                            | 0.01 giờ                                         | 1.5 giờ                                            | 0.02 giờ                                       |\n","| **Precision**            | Tỉ lệ giữa số dự đoán đúng (true positives) và tổng số các dự đoán (true positives + false positives). Precision cao nghĩa là mô hình ít dự đoán sai. | Precision cao thể hiện độ chính xác của mô hình trong việc đưa ra dự đoán đúng.                           | 0.526                            | 0.808                                                | 0.865                                               | 0.904                                             | 0.912                                               | 0.889                                            |\n","| **Recall**               | Tỉ lệ giữa số dự đoán đúng và tổng số đối tượng thực sự có (true positives + false negatives). Recall cao nghĩa là mô hình phát hiện tốt các đối tượng. | Recall cao thể hiện khả năng phát hiện đầy đủ các đối tượng trong dữ liệu.                                | 0.333                            | 0.713                                                | 0.811                                               | 0.597                                             | 0.867                                               | 0.829                                            |\n","| **mAP@0.5**              | Mean Average Precision tại ngưỡng IoU = 0.5, đo lường độ chính xác của dự đoán khi yêu cầu độ chồng lấn giữa các hộp giới hạn là 50%. | mAP@0.5 cao cho thấy mô hình có khả năng phát hiện tốt các đối tượng với độ chính xác hộp giới hạn (bounding boxes). | 0.526                            | 0.808                                                | 0.898                                               | 0.904                                             | 0.921                                               | 0.892                                            |\n","| **mAP@0.5:0.95**         | Mean Average Precision trung bình qua nhiều ngưỡng IoU từ 0.5 đến 0.95. Chỉ số này phản ánh khả năng dự đoán chính xác với các mức độ chồng lấn khác nhau. | mAP@0.5:0.95 cao thể hiện khả năng tổng quát hóa tốt của mô hình, đặc biệt trong các bài toán có các đối tượng chồng lấn. | 0.333                            | 0.499                                                | 0.618                                               | 0.597                                             | 0.652                                               | 0.628                                            |\n","\n"]},{"cell_type":"markdown","metadata":{},"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30787,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
